{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "$$ \\LaTeX \\text{ command declarations here.}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\renewcommand{\\vec}[1]{\\mathbf{#1}}\n",
    "\\newcommand{\\X}{\\mathcal{X}}\n",
    "\\newcommand{\\D}{\\mathcal{D}}\n",
    "\\newcommand{\\G}{\\mathcal{G}}\n",
    "\\newcommand{\\L}{\\mathcal{L}}\n",
    "\\newcommand{\\X}{\\mathcal{X}}\n",
    "\\newcommand{\\Parents}{\\mathrm{Parents}}\n",
    "\\newcommand{\\NonDesc}{\\mathrm{NonDesc}}\n",
    "\\newcommand{\\I}{\\mathcal{I}}\n",
    "\\newcommand{\\dsep}{\\text{d-sep}}\n",
    "\\newcommand{\\Cat}{\\mathrm{Categorical}}\n",
    "\\newcommand{\\Bin}{\\mathrm{Binomial}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# HMMs and the Baum-Welch Algorithm\n",
    "\n",
    "As covered in lecture, the Baum-Welch Algorithm is a derivation of the EM algorithm for HMMs where we learn the paramaters A, B and $\\pi$ given a set of observations.\n",
    "\n",
    "In this hands-on exercise we will **build upon the forward and backward algorithms from last exercise**, which can be used for the E-step, and implement Baum-Welch ourselves!\n",
    "\n",
    "Like last time, we'll work with an example where we observe a sequence of words backed by a latent part of speech variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$X$: discrete distribution over bag of words\n",
    "\n",
    "$Z$: discrete distribution over parts of speech\n",
    "\n",
    "$A$: the probability of a part of speech given a previous part of speech, e.g, what do we expect to see after a noun? \n",
    "\n",
    "$B$: the distribution of words given a particular part of speech, e.g, what words are we likely to see if we know it is a verb?\n",
    "\n",
    "$x_{i}s$ a sequence of observed words (a sentence). Note: in for both variables we have a special \"end\" outcome that signals the end of a sentence. This makes sense as a part of speech tagger would like to have a sense of sentence boundaries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review: Forward / Backward\n",
    "\n",
    "Here are solutions to last hands-on lecture's coding problems along with example uses with a pre-defined A and B matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "parts_of_speech = DETERMINER, NOUN, VERB, END = 0, 1, 2, 3\n",
    "words = THE, DOG, CAT, WALKED, RAN, IN, PARK, END = 0, 1, 2, 3, 4, 5, 6, 7\n",
    "\n",
    "# transition probabilities\n",
    "A = np.array([\n",
    "        # D     N   V   E\n",
    "        [0.1, 0.8, 0.1, 0.0],  # D: determiner most likely to go to noun\n",
    "        [0.1, 0.1, 0.6, 0.2],  # N: noun most likely to go to verb\n",
    "        [0.4, 0.3, 0.2, 0.1],  # V \n",
    "        [0.0, 0.0, 0.0, 1.0]]) # E: end always goes to end\n",
    "\n",
    "# distribution of parts of speech for the first word of a sentence\n",
    "pi = np.array([0.4, 0.3, 0.3, 0.0])\n",
    "\n",
    "# emission probabilities\n",
    "B = np.array([\n",
    "        # D     N     V     E\n",
    "        [ 0.8,  0.1,  0.1,  0. ],  # the\n",
    "        [ 0.1,  0.8,  0.1,  0. ],  # dog\n",
    "        [ 0.1,  0.8,  0.1,  0. ],  # cat\n",
    "        [ 0. ,  0. ,  1. ,  0. ],  # walked\n",
    "        [ 0. ,  0.2 , 0.8 ,  0. ], # ran\n",
    "        [ 1. ,  0. ,  0. ,  0. ],  # in\n",
    "        [ 0. ,  0.1,  0.9,  0. ],  # park\n",
    "        [ 0. ,  0. ,  0. ,  1. ]]) # end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     D    N    V    E\n",
      "D  0.1  0.8  0.1  0.0\n",
      "N  0.1  0.1  0.6  0.2\n",
      "V  0.4  0.3  0.2  0.1\n",
      "E  0.0  0.0  0.0  1.0\n",
      "          D    N    V    E\n",
      "the     0.8  0.1  0.1  0.0\n",
      "dog     0.1  0.8  0.1  0.0\n",
      "cat     0.1  0.8  0.1  0.0\n",
      "walked  0.0  0.0  1.0  0.0\n",
      "ran     0.0  0.2  0.8  0.0\n",
      "in      1.0  0.0  0.0  0.0\n",
      "park    0.0  0.1  0.9  0.0\n",
      "end     0.0  0.0  0.0  1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pos_labels = [\"D\", \"N\", \"V\", \"E\"]\n",
    "word_labels = [\"the\", \"dog\", \"cat\", \"walked\", \"ran\", \"in\", \"park\", \"end\"]\n",
    "\n",
    "def print_B(B):\n",
    "    print(pd.DataFrame(B, columns=pos_labels, index=word_labels))\n",
    "    \n",
    "def print_A(A):\n",
    "    print(pd.DataFrame(A, columns=pos_labels, index=pos_labels))\n",
    "        \n",
    "print_A(A)\n",
    "print_B(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               D         N         V        E\n",
      "the     0.320000  0.030000  0.030000  0.00000\n",
      "dog     0.004700  0.214400  0.005600  0.00000\n",
      "walked  0.000000  0.000000  0.130230  0.00000\n",
      "in      0.052092  0.000000  0.000000  0.00000\n",
      "the     0.004167  0.004167  0.000521  0.00000\n",
      "park    0.000000  0.000391  0.002719  0.00000\n",
      "end     0.000000  0.000000  0.000000  0.00035\n",
      "             D         N         V         E\n",
      "the   0.320000  0.030000  0.030000  0.000000\n",
      "cat   0.004700  0.214400  0.005600  0.000000\n",
      "ran   0.000000  0.005376  0.104184  0.000000\n",
      "in    0.042211  0.000000  0.000000  0.000000\n",
      "the   0.003377  0.003377  0.000422  0.000000\n",
      "park  0.000000  0.000317  0.002203  0.000000\n",
      "end   0.000000  0.000000  0.000000  0.000284\n"
     ]
    }
   ],
   "source": [
    "def forward(params, observations):\n",
    "    pi, A, B = params\n",
    "    N = len(observations)\n",
    "    S = pi.shape[0]\n",
    "    \n",
    "    alpha = np.zeros((N, S))\n",
    "    \n",
    "    # base case\n",
    "    alpha[0, :] = pi * B[observations[0], :]\n",
    "    \n",
    "    # recursive case\n",
    "    for i in range(1, N):\n",
    "        for s2 in range(S):\n",
    "            for s1 in range(S):\n",
    "                alpha[i, s2] += alpha[i-1, s1] * A[s1, s2] * B[observations[i], s2]    \n",
    "    \n",
    "    return (alpha, np.sum(alpha[N-1,:]))\n",
    "\n",
    "def print_forward(params, observations):\n",
    "    alpha, za = forward(params, observations)\n",
    "    print(pd.DataFrame(\n",
    "            alpha, \n",
    "            columns=pos_labels, \n",
    "            index=[word_labels[i] for i in observations]))\n",
    "\n",
    "print_forward((pi, A, B), [THE, DOG, WALKED, IN, THE, PARK, END])\n",
    "print_forward((pi, A, B), [THE, CAT, RAN, IN, THE, PARK, END])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.00104026,  0.00016397,  0.00040858,  0.        ],\n",
       "        [ 0.0002688 ,  0.0016128 ,  0.0005376 ,  0.        ],\n",
       "        [ 0.000672  ,  0.000672  ,  0.002688  ,  0.        ],\n",
       "        [ 0.00672   ,  0.004     ,  0.01016   ,  0.        ],\n",
       "        [ 0.025     ,  0.056     ,  0.024     ,  0.        ],\n",
       "        [ 0.        ,  0.2       ,  0.1       ,  1.        ],\n",
       "        [ 1.        ,  1.        ,  1.        ,  1.        ]]),\n",
       " 0.00035005824000000022)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def backward(params, observations):\n",
    "    pi, A, B = params\n",
    "    N = len(observations)\n",
    "    S = pi.shape[0]\n",
    "    \n",
    "    beta = np.zeros((N, S))\n",
    "    \n",
    "    # base case\n",
    "    beta[N-1, :] = 1\n",
    "    \n",
    "    # recursive case\n",
    "    for i in range(N-2, -1, -1):\n",
    "        for s1 in range(S):\n",
    "            for s2 in range(S):\n",
    "                beta[i, s1] += beta[i+1, s2] * A[s1, s2] * B[observations[i+1], s2]\n",
    "    \n",
    "    return (beta, np.sum(pi * B[observations[0], :] * beta[0,:]))\n",
    "\n",
    "backward((pi, A, B), [THE, DOG, WALKED, IN, THE, PARK, END])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some utitlities for tracing our implementation below\n",
    "\n",
    "def left_pad(i, s):\n",
    "    return \"\\n\".join([\"{}{}\".format(' '*i, l) for l in s.split(\"\\n\")])\n",
    "\n",
    "def pad_print(i, s):\n",
    "    print(left_pad(i, s))\n",
    "    \n",
    "def pad_print_args(i, **kwargs):\n",
    "    pad_print(i, \"\\n\".join([\"{}:\\n{}\".format(k, kwargs[k]) for k in sorted(kwargs.keys())]))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def baum_welch(training, pi, A, B, iterations, trace=False):\n",
    "    pi, A, B = np.copy(pi), np.copy(A), np.copy(B)  # take copies, as we modify them\n",
    "    S = pi.shape[0]\n",
    "\n",
    "    # iterations of EM\n",
    "    for it in range(iterations):\n",
    "        if trace:\n",
    "            pad_print(0, \"for it={} in range(iterations)\".format(it))\n",
    "            pad_print_args(2, A=A, B=B, pi=pi, S=S)\n",
    "        pi1 = np.zeros_like(pi)\n",
    "        A1 = np.zeros_like(A)\n",
    "        B1 = np.zeros_like(B)\n",
    "\n",
    "        for observations in training:\n",
    "            if trace:\n",
    "                pad_print(2, \"for observations={} in training\".format(observations))\n",
    "\n",
    "            # compute forward-backward matrices\n",
    "            alpha, za = forward((pi, A, B), observations)\n",
    "            beta, zb = backward((pi, A, B), observations)\n",
    "            if trace:\n",
    "                pad_print(4, \"\"\"alpha, za = forward((pi, A, B), observations)\\nbeta, zb = backward((pi, A, B), observations)\"\"\")\n",
    "                pad_print_args(4, alpha=alpha, beta=beta, za=za, zb=zb)\n",
    "\n",
    "            assert abs(za - zb) < 1e-6, \"it's badness 10000 if the marginals don't agree ({} vs {})\".format(za, zb)\n",
    "\n",
    "            # M-step here, calculating the frequency of starting state, transitions and (state, obs) pairs\n",
    "            \n",
    "            # Update PI\n",
    "            pi1 += alpha[0, :] * beta[0, :] / za\n",
    "\n",
    "            if trace:\n",
    "                pad_print(4, \"pi1 += alpha[0, :] * beta[0, :] / za\")\n",
    "                pad_print_args(4, pi1=pi1)\n",
    "                pad_print(4, \"for i in range(0, len(observations)):\")\n",
    "            \n",
    "            # Update B (transition) matrix\n",
    "            for i in range(0, len(observations)):\n",
    "                B1[observations[i], :] += alpha[i, :] * beta[i, :] / za\n",
    "                if trace:\n",
    "                    pad_print(6, \"B1[observations[{i}], :] += alpha[{i}, :] * beta[{i}, :] / za\".format(i=i))\n",
    "            if trace:\n",
    "                pad_print_args(4, B1=B1)\n",
    "                pad_print(4, \"for i in range(1, len(observations)):\")\n",
    "                \n",
    "            # Update A (emission) matrix\n",
    "            for i in range(1, len(observations)):\n",
    "                if trace: \n",
    "                    pad_print(6, \"for s1 in range(S={})\".format(S))\n",
    "                for s1 in range(S):\n",
    "                    if trace: pad_print(8, \"for s2 in range(S={})\".format(S))\n",
    "                    for s2 in range(S):\n",
    "                        A1[s1, s2] += alpha[i - 1, s1] * A[s1, s2] * B[observations[i], s2] * beta[i, s2] / za\n",
    "                        if trace: pad_print(10, \"A1[{s1}, {s2}] += alpha[{i_1}, {s1}] * A[{s1}, {s2}] * B[observations[{i}], {s2}] * beta[{i}, {s2}] / za\".format(s1=s1, s2=s2, i=i, i_1=i-1))\n",
    "            if trace: pad_print_args(4, A1=A1)\n",
    "\n",
    "        # normalise pi1, A1, B1\n",
    "        pi = pi1 / np.sum(pi1)\n",
    "        for s in range(S):\n",
    "            A[s, :] = A1[s, :] / np.sum(A1[s, :])\n",
    "            B[s, :] = B1[s, :] / np.sum(B1[s, :])\n",
    "        \n",
    "    return pi, A, B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training with examples\n",
    "\n",
    "Let's try producing updated parameters to our HMM using a few examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original A\n",
      "     D    N    V    E\n",
      "D  0.1  0.8  0.1  0.0\n",
      "N  0.1  0.1  0.6  0.2\n",
      "V  0.4  0.3  0.2  0.1\n",
      "E  0.0  0.0  0.0  1.0\n",
      "updated A\n",
      "     D    N    V    E\n",
      "D  0.0  1.0  0.0  0.0\n",
      "N  0.0  0.0  1.0  0.0\n",
      "V  0.5  0.0  0.0  0.5\n",
      "E  0.0  0.0  0.0  1.0\n",
      "\n",
      "original B\n",
      "          D    N    V    E\n",
      "the     0.8  0.1  0.1  0.0\n",
      "dog     0.1  0.8  0.1  0.0\n",
      "cat     0.1  0.8  0.1  0.0\n",
      "walked  0.0  0.0  1.0  0.0\n",
      "ran     0.0  0.2  0.8  0.0\n",
      "in      1.0  0.0  0.0  0.0\n",
      "park    0.0  0.1  0.9  0.0\n",
      "end     0.0  0.0  0.0  1.0\n",
      "updated B\n",
      "          D    N    V    E\n",
      "the     0.5  0.5  0.0  0.0\n",
      "dog     0.0  1.0  0.0  0.0\n",
      "cat     0.0  1.0  0.0  0.0\n",
      "walked  0.0  0.0  1.0  0.0\n",
      "ran     0.0  0.2  0.8  0.0\n",
      "in      1.0  0.0  0.0  0.0\n",
      "park    0.0  0.1  0.9  0.0\n",
      "end     0.0  0.0  0.0  1.0\n",
      "           D      N       V        E\n",
      "the     0.50  0.000  0.0000  0.00000\n",
      "dog     0.00  0.500  0.0000  0.00000\n",
      "walked  0.00  0.000  0.5000  0.00000\n",
      "in      0.25  0.000  0.0000  0.00000\n",
      "the     0.00  0.125  0.0000  0.00000\n",
      "park    0.00  0.000  0.1125  0.00000\n",
      "end     0.00  0.000  0.0000  0.05625\n"
     ]
    }
   ],
   "source": [
    "pi2, A2, B2 = baum_welch([\n",
    "        [THE, DOG, WALKED, IN, THE, PARK, END, END], # END -> END needs at least one transition example\n",
    "        [THE, DOG, RAN, IN, THE, PARK, END],\n",
    "        [THE, CAT, WALKED, IN, THE, PARK, END],\n",
    "        [THE, DOG, RAN, IN, THE, PARK, END]], pi, A, B, 10, trace=False)\n",
    "\n",
    "print(\"original A\")\n",
    "print_A(A)\n",
    "\n",
    "print(\"updated A\")\n",
    "print_A(A2)\n",
    "\n",
    "print(\"\\noriginal B\")\n",
    "print_B(B)\n",
    "\n",
    "print(\"updated B\")\n",
    "print_B(B2)\n",
    "\n",
    "print_forward((pi2, A2, B2), [THE, DOG, WALKED, IN, THE, PARK, END])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
